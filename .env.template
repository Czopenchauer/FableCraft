# =============================================================================
# FableCraft Docker Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.template .env
#
# Variables in this file override those in service-specific env files
# (e.g., GraphRag/.env.docker)
# =============================================================================

# =============================================================================
# LLM CONFIGURATION (Required)
# =============================================================================
# Your LLM provider API key - REQUIRED
LLM_API_KEY=

# LLM provider: openai, azure, anthropic, google, etc.
LLM_PROVIDER=openai

# Model to use for text generation
# Examples: gpt-4, gpt-4o, claude-3-opus, gemini-pro
LLM_MODEL=gpt-4

# Maximum tokens for LLM responses
LLM_MAX_TOKENS=16384

# =============================================================================
# LLM ENDPOINT (Optional - for Azure OpenAI or custom endpoints)
# =============================================================================
# Base URL for the LLM API (leave empty for default OpenAI endpoint)
# Azure example: https://your-resource.openai.azure.com
LLM_ENDPOINT=

# API version (required for Azure OpenAI)
# Example: 2024-02-15-preview
LLM_API_VERSION=

# =============================================================================
# LLM RATE LIMITING (Optional)
# =============================================================================
# Enable rate limiting to avoid hitting API limits
LLM_RATE_LIMIT_ENABLED=true

# Maximum requests per interval
LLM_RATE_LIMIT_REQUESTS=60

# Interval in seconds
LLM_RATE_LIMIT_INTERVAL=60

# =============================================================================
# EMBEDDING CONFIGURATION (Required for GraphRag)
# =============================================================================
# Embedding provider: openai, azure, huggingface, etc.
EMBEDDING_PROVIDER=openai

# Embedding model name
# Examples: text-embedding-3-large, text-embedding-ada-002
EMBEDDING_MODEL=text-embedding-3-large

# Embedding dimensions (must match your model)
# text-embedding-3-large: 3072, text-embedding-ada-002: 1536
EMBEDDING_DIMENSIONS=3072

# Maximum tokens per embedding request
EMBEDDING_MAX_TOKENS=8191

# Batch size for embedding requests
EMBEDDING_BATCH_SIZE=36

# =============================================================================
# EMBEDDING ENDPOINT (Optional - for Azure or custom endpoints)
# =============================================================================
# Base URL for embeddings API (leave empty for default)
EMBEDDING_ENDPOINT=

# API version for embeddings (required for Azure)
EMBEDDING_API_VERSION=

# =============================================================================
# HUGGINGFACE (Optional)
# =============================================================================
# HuggingFace tokenizer to use (leave empty for default)
HUGGINGFACE_TOKENIZER=

# =============================================================================
# LANGFUSE (Optional - for LLM observability)
# =============================================================================
# Langfuse public key for tracing
LANGFUSE_PUBLIC_KEY=default

# Langfuse secret key
LANGFUSE_SECRET_KEY=default

# =============================================================================
# DATABASE (Optional - defaults provided)
# =============================================================================
# PostgreSQL credentials (change in production!)
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=fablecraftdb

# =============================================================================
# ASPIRE EXTERNAL DATABASE (Optional)
# =============================================================================
# Set to "true" when running Aspire alongside Docker Compose PostgreSQL
# This tells Aspire to connect to an existing database instead of creating one
# FABLECRAFT_USE_EXTERNAL_DATABASE=true
#
# Connection string for external database (when USE_EXTERNAL_DATABASE=true)
# CONNECTIONSTRINGS__FABLECRAFTDB=Host=localhost;Port=6999;Database=fablecraftdb;Username=postgres;Password=postgres

# =============================================================================
# SERVER CONFIGURATION (Optional)
# =============================================================================
# Server LLM configuration (if different from GraphRag)
# SERVER_LLM_MODEL=gpt-4
# SERVER_LLM_API_KEY=
# SERVER_LLM_BASE_URL=

# =============================================================================
# OBSERVABILITY (Optional)
# =============================================================================
# Seq endpoints for logging (if using Seq instead of Aspire Dashboard)
# FABLECRAFT_EXPORTER_SEQ_TRACE_ENDPOINT=http://seq:5341/ingest/otlp/v1/traces
# FABLECRAFT_EXPORTER_SEQ_LOG_ENDPOINT=http://seq:5341

# =============================================================================
# PORTS (Optional - defaults provided)
# =============================================================================
# Uncomment to change default ports
# DASHBOARD_PORT=18888
# SERVER_PORT=5000
# CLIENT_PORT=4200
# GRAPHRAG_PORT=8111
# POSTGRES_PORT=6999
